Partitioning in Hive is very useful to prune data during query to reduce query times.

Partitions are created when data is inserted into table. Depending on how you load data you would need partitions. 
Usually when loading files (big files) into Hive tables static partitions are preferred. 
That saves your time in loading data compared to dynamic partition. 
You "statically" add a partition in table and move the file into the partition of the table. 
Since the files are big they are usually generated in HDFS. 
You can get the partition column value form the filename, day of date etc without reading the whole big file.

Incase of dynamic partition whole big file i.e. every row of the data is read and data is partitioned 
through a MR job into the destination tables depending on certain field in file. 
So usually dynamic partition are useful when you are doing sort of a ETL flow in your data pipeline. e.g.
you load a huge file through a move command into a Table X. then you run a inert query into a Table Y and 
partition data based on field in table X say day , country. You may want to further run a ETL step to partition 
the data in country partition in Table Y into a Table Z where data is partitioned based on cities for a particular country only. etc.

Thus depending on your end table or requirements for data and in what form data is produced at source you may choose static 
or dynamic partition.


in static partitioning we need to specify the partition column value in each and every LOAD statement.

suppose we are having partition on column country for table t1(userid, name,occupation, country), so each time we need to provide country value

hive>LOAD DATA INPATH '/hdfs path of the file' INTO TABLE t1 PARTITION(country="US")
hive>LOAD DATA INPATH '/hdfs path of the file' INTO TABLE t1 PARTITION(country="UK")
dynamic partition allow us not to specify partition column value each time. the approach we follows is as below:

create a non-partitioned table t2 and insert data into it.
now create a table t1 partitioned on intended column(say country).
load data in t1 from t2 as below:

hive> INSERT INTO TABLE t2 PARTITION(country) SELECT * from T1;
make sure that partitioned column is always the last one in non partitioned table(as we are having country column in t2)



We can alter the partition in static partition

You can get the partition column value form the filename, day of date etc without reading the whole big file. If you want to use Static partition in hive you should set property

set hive.mapred.mode = strict
This property set by default in hive-site.xml Static partition is in Strict Mode You should use where clause to use limit in static partition You can perform Static partition on Hive Manage table or external table.

Dynamic Partition in Hive

single insert to partition table is known as dynamic partition

Usually dynamic partition load the data from non partitioned table

Dynamic Partition takes more time in loading data compared to static partition

When you have large data stored in a table then Dynamic partition is suitable.

If you want to partition number of column but you don’t know how many columns then also dynamic partition is suitable

Dynamic partition there is no required where clause to use limit. we can’t perform alter on Dynamic partition

You can perform dynamic partition on hive external table and managed table If you want to use Dynamic partition in hive then mode is in nonstrict mode Here is hive dynamic partition properties you should allow

SET hive.exec.dynamic.partition = true;

SET hive.exec.dynamic.partition.mode = nonstrict;



For dynamic partitioning, you have to use INSERT ... SELECT query (Hive insert).

Inserting data into Hive table having DP, is a two step process.

Create staging table in staging database in hive and load data into that table from external source such as RDBMS, document database or local files using Hive load.
Insert data into actual table into ODS (operational data store/final database) using Hive insert.
Also, set following properties in Hive.

SET hive.exec.dynamic.partition=true;
SET hive.exec.dynamic.partition.mode=nonstrict;
Following example works on cloudera VM.

-- Extract orders data from mysql (Retail_DB.products) 
select * from orders into outfile '/tmp/orders_data.psv' fieldsterminated by '|' lines terminated by 'n';

-- Create Hive table with DP - order_month is DP.
CREATE TABLE orders (order_id int, order_date string, order_customer_id int, order_status string ) PARTITIONED BY (order_month string) ROW FORMAT DELIMITED FIELDS TERMINATED BY '|'STORED AS TEXTFILE;

--Create staging table in Hive.
CREATE TABLE orders_stage (order_id int,order_date string, order_customer_id int, order_status string ) ROW FORMAT DELIMITED FIELDS TERMINATED BY '|' STORED AS TEXTFILE;

--Load data into staging table (Hive)
Load data into staging table  load data local inpath 
/tmp/orders_data.psv' overwrite into table orders_stage;

--Insert into Orders, which is final table (Hive). 
Insert overwrite table retail_ods.orders partition (order_month)
select order_id, order_date, order_customer_id,order_status,
substr(order_date, 1, 7) order_month from retail_stage.orders_stage;
You can find more details at https://cwiki.apache.org/confluence/display/Hive/DynamicPartitions

Nikhil Bhide
53055 silver badges1919 bronze badges
can we do it without using a staging table?.. like directly load data from a file to table with dynamic partitioning. 

– Naman Bhargava Dec 30 '16 at 14:35
No you cant, a simple reason to it is ,the schema information. Hive will not have any schema info from the data stored in
the file. Staging table unload gives the schema info, which in turn gives hive info about the column which should be used 
to divide data into partitions.
